{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.array([[0,0],[0,1],[1,0],[1,1]]).astype(float)\n",
    "train_labels = np.array([[0],[1],[1],[0]]).astype(float)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph = tf.Graph()\n",
    "# with graph.as_default():\n",
    "    # X_data = tf.constant(train_dataset)\n",
    "    # y_data = tf.constant(train_labels)\n",
    "    \n",
    "    # X_data = tf.constant([0.0,0.0, 0.0,1.0, 1.0,0.0, 1.0,1.0], shape=[4,2])\n",
    "    # y_data = tf.constant([0.0,1.0,1.0,0.0])\n",
    "    \n",
    "# X_data = np.array([[0,0],[0,1],[1,0],[1,1]]).astype(np.float32)\n",
    "# y_data = np.array([0,1,1,0]).astype(np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[4,2])\n",
    "y = tf.placeholder(tf.float32, shape=[4,1])\n",
    "\n",
    "def prediction(X,W1,b1,W2,b2):\n",
    "    h = tf.matmul(X,W1) + b1\n",
    "    r = tf.nn.relu(h)\n",
    "    return tf.matmul(r,W2) + b2\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2,2], 1.0, 0.1))\n",
    "b1 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([2,1], 1.0, 0.1))\n",
    "b2 = tf.Variable(tf.zeros([1]))\n",
    "    \n",
    "# Minimize the mean squared errors\n",
    "loss = tf.reduce_mean(tf.square(prediction(X,W1,b1,W2,b2) - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "train_prediction = prediction(X, W1, b1, W2, b2)\n",
    "    \n",
    "summary_writer = tf.train.SummaryWriter('xor', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.343238 with predictions =  [[ 0.        ]\n",
      " [ 0.40042663]\n",
      " [ 0.1715921 ]\n",
      " [ 0.57201874]]\n",
      "Loss at step 20: 0.267471 with predictions =  [[ 0.2990765 ]\n",
      " [ 0.52778524]\n",
      " [ 0.42161924]\n",
      " [ 0.65032792]]\n",
      "Loss at step 40: 0.256243 with predictions =  [[ 0.37856627]\n",
      " [ 0.50888324]\n",
      " [ 0.46361178]\n",
      " [ 0.59392881]]\n",
      "Loss at step 60: 0.252542 with predictions =  [[ 0.42176002]\n",
      " [ 0.49860799]\n",
      " [ 0.48494774]\n",
      " [ 0.56179571]]\n",
      "Loss at step 80: 0.251137 with predictions =  [[ 0.44776961]\n",
      " [ 0.49304286]\n",
      " [ 0.49667811]\n",
      " [ 0.5419513 ]]\n",
      "Loss at step 100: 0.250561 with predictions =  [[ 0.46416491]\n",
      " [ 0.49030095]\n",
      " [ 0.50311196]\n",
      " [ 0.529248  ]]\n",
      "Loss at step 120: 0.250308 with predictions =  [[ 0.47476271]\n",
      " [ 0.48925295]\n",
      " [ 0.50644863]\n",
      " [ 0.52093881]]\n",
      "Loss at step 140: 0.250188 with predictions =  [[ 0.48174429]\n",
      " [ 0.48919043]\n",
      " [ 0.5079565 ]\n",
      " [ 0.51540267]]\n",
      "Loss at step 160: 0.250124 with predictions =  [[ 0.48643038]\n",
      " [ 0.48967186]\n",
      " [ 0.50839949]\n",
      " [ 0.51164097]]\n",
      "Loss at step 180: 0.250087 with predictions =  [[ 0.48964137]\n",
      " [ 0.49042752]\n",
      " [ 0.50824177]\n",
      " [ 0.50902796]]\n",
      "Loss at step 200: 0.250063 with predictions =  [[ 0.49189317]\n",
      " [ 0.4912965 ]\n",
      " [ 0.50776434]\n",
      " [ 0.50716764]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "#     for step in range(201):\n",
    "#         sess.run(train)\n",
    "#         if step % 20 == 0:\n",
    "#             print(step, sess.run(W), sess.run(b))\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "for step in range(201):\n",
    "    feed_dict = {X : train_dataset, y : train_labels}\n",
    "    _, l, predictions, weights1, bias1, weights2, bias2 = sess.run([optimizer, loss, train_prediction, W1, b1, W2, b2], feed_dict=feed_dict)\n",
    "\n",
    "    if step % 20 == 0:\n",
    "        print('Loss at step %d: %f with predictions = ' % (step,l), predictions)\n",
    "#         print(weights1)\n",
    "#         print(bias1)\n",
    "#         print(weights2)\n",
    "#         print(bias2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
